# ğŸ” ai-llm-rag-system

This repository is dedicated to experimenting with and testing various **RAG (Retrieval-Augmented Generation)** architectures using modern **LLMs** and vector databases. It provides a modular framework for building, evaluating, and interacting with systems that combine local knowledge sources and generative models.

---

## ğŸ“¦ Features

- ğŸ”— **Retrieval-Augmented Generation (RAG)**: Integrates vector search (via ChromaDB) with text generation (Hugging Face Transformers).
- ğŸ§  **LLM Integration**: Utilizes models like `google/gemma-2-2b-it` for high-quality generation.
- ğŸ—‚ï¸ **Long-term Knowledge Handling**: Automatically chunks and indexes documents from a local folder.
- ğŸ’¬ **Interactive Dialog Interface**: Terminal-based assistant that retrieves relevant context and generates informed answers.
- ğŸ› ï¸ **Modular Design**: Easily swap models, vector DBs, or prompt templates.

---

## ğŸ§° Tech Stack

- ğŸ¤— **LLM Transformers** â€” Text generation pipeline.
- ğŸ§  **ChromaDB** â€” Lightweight in-memory vector database for similarity search.
- ğŸ§© **LangChain** â€” Used for efficient and intelligent text chunking.
- ğŸ **Python** â€” Main development language.